@article{patro_2015_normalization,
  author = {Patro, S. Gopal Krishna and Sahu, Kishore Kumar},
  month = {03},
  title = {Normalization: A Preprocessing Stage},
  url = {https://arxiv.org/abs/1503.06462},
  year = {2015},
  journal = {arXiv:1503.06462 [cs]}
}

@misc{fernando_2024_rsquared,
  author = {Fernando, Jason},
  month = {11},
  title = {R-Squared: Definition, Calculation Formula, Uses, and Limitations},
  url = {https://www.investopedia.com/terms/r/r-squared.asp},
  year = {2024},
  organization = {Investopedia}
}

@article{yeo2000new,
  title={A new family of power transformations to improve normality or symmetry},
  author={Yeo, In-Kwon and Johnson, Richard A},
  journal={Biometrika},
  volume={87},
  number={4},
  pages={954--959},
  year={2000},
  publisher={Oxford University Press}
}


@article{kapoor_genetic_2024,
	title = {A genetic programming approach to the automated design of {CNN} models for image classification and video shorts creation},
	volume = {25},
	issn = {1573-7632},
	url = {https://doi.org/10.1007/s10710-024-09483-5},
	doi = {10.1007/s10710-024-09483-5},
	abstract = {Neural architecture search (NAS) is a rapidly growing field which focuses on the automated design of neural network architectures. Genetic algorithms (GAs) have been predominantly used for evolving neural network architectures. Genetic programming (GP), a variation of GAs that work in the program space rather than a solution space, has not been as well researched for NAS. This paper aims to contribute to the research into GP for NAS. Previous research in this field can be divided into two categories. In the first each program represents neural networks directly or components and parameters of neural networks. In the second category each program is a set of instructions, which when executed, produces a neural network. This study focuses on this second category which has not been well researched. Previous work has used grammatical evolution for generating these programs. This study examines canonical GP for neural network design (GPNND) for this purpose. It also evaluates a variation of GP, iterative structure-based GP (ISBGP) for evolving these programs. The study compares the performance of GAs, GPNND and ISBGP for image classification and video shorts creation. Both GPNND and ISBGP were found to outperform GAs, with ISBGP producing better results than GPNND for both applications. Both GPNND and ISBGP produced better results than previous studies employing grammatical evolution on the CIFAR-10 dataset.},
	number = {1},
	journal = {Genetic Programming and Evolvable Machines},
	author = {Kapoor, Rahul and Pillay, Nelishia},
	month = mar,
	year = {2024},
	pages = {10},
}

